\begin{table}[ht]
\centering
\begin{tabular}{|l|c|c|c|c|}
\hline

\bf Method                    & \bf Precision & \bf Recall & \bf F1-Score & \bf Accuracy \\ \hline
    @ w/o linking resolution  &     79.92     &     77.44  &     78.64    &     92.79    \\ \hline
    \# w/o linking resolution &     76.23     &     81.35  &     78.68    &     92.46    \\ \hline
    @len-score                & \bf 81.84     &     75.66  &     78.60    & \bf 92.96    \\ \hline
    \#len-score               &     77.27     &     80.45  &     78.81    &     92.61    \\

\hhline{|=|=|=|=|=|}

    Li et al. maximum entropy &     78.80     &     61.80  &     69.20    &     87.20    \\ \hline
    Li et al. decision tree   &     56.80     &     49.60  &     52.30    &     88.40    \\

\hhline{|=|=|=|=|=|}

    Zhou et al.               &               &            &     79.33    &     70.43    \\ \hline
    Li, M \& N                &     78.57     & \bf 81.48  & \bf 80.00    &     82.04    \\ \hline

\end{tabular}
\begin{flushleft}
\small
\textbf{@}: disambiguation on component level \\
\textbf{\#}: disambiguation on connective level \\
\end{flushleft}
\caption{\label{t:recognition-methods} Performance of discourse usage
disambiguation for connective components by methods. }
\end{table}
