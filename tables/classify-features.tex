\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|c|}
\hline

\bf Features            & \bf Precision & \bf Recall & \bf F1-Score \\ \hline
    P \& N              &     48.73     &     75.73  &     59.26    \\ \hline
    POS                 &     62.64     &     70.98  &     66.52    \\ \hline
    NUM                 &     46.80     & \bf 78.87  &     58.71    \\ \hline
    SKIPGRAM            &     69.20     &     72.79  &     70.93    \\ \hline
    All-P \& N          &     72.24     &     76.48  &     74.27    \\ \hline
    All-POS             &     72.43     &     76.59  &     74.43    \\ \hline
    All-NUM             &     71.86     &     73.85  &     72.83    \\ \hline
    All-SKIPGRAM        &     64.09     &     76.37  &     69.65    \\ \hline
    All                 & \bf 73.30     &     76.75  & \bf 74.97    \\ \hline


\end{tabular}
\caption{\label{t:classify-features} Performance of discourse linking
disambiguation for connectives by different features.} This is done by
treating each connective as an instance then classify their discourse usage
by logistic regression. Aftwards, we rank each candidate by length and their
logistic probability and reject overlappped ones.
\end{table}

