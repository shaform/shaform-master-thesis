\begin{table}[ht]
\centering
\begin{tabular}{|l|c|c|c|}
\hline

Model                  &     Precision &     Recall &     F1-Score                 \\ \hline
Gaussian Naive Bayes   &     42.35     & \bf 92.17  &     58.02\textsuperscript{*} \\ \hline
SVM with RBF kernel    &     80.00     &     69.84  &     74.55\textsuperscript{*} \\ \hline
SVM with linear kernel &     75.75     &     74.71  &     75.20\textsuperscript{*} \\ \hline
Decision Tree          &     74.85     &     73.83  &     74.98\textsuperscript{*} \\ \hline
Random Forest          & \bf 83.25     &     72.09  &     77.20\textsuperscript{*} \\ \hline
Logistic Regression    &     79.92     &     77.44  & \bf 78.64\textsuperscript{!} \\ \hline

\end{tabular}
\caption{\label{t:recognition-models} Performance of discourse usage
disambiguation on component level using different learning models. }
\end{table}
